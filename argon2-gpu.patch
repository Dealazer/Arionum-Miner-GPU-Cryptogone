diff --git a/CMakeLists.txt b/CMakeLists.txt
index 3dd95ba..15fb786 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -28,9 +28,17 @@ if(CUDA_FOUND)
     )
 endif()
 
+FIND_PACKAGE(OpenCL)
+INCLUDE_DIRECTORIES(${OPENCL_INCLUDE_DIR})
+if (OPENCL_FOUND)
+    message("INFO: Using OPENCL version ${OpenCL_VERSION_MAJOR}.${OpenCL_VERSION_MINOR}")
+else()
+    message("INFO: OPENCL not found")
+endif()
+
 add_subdirectory(ext/argon2)
 
-add_library(argon2-gpu-common SHARED
+add_library(argon2-gpu-common STATIC
     lib/argon2-gpu-common/argon2params.cpp
     lib/argon2-gpu-common/blake2b.cpp
 )
@@ -44,7 +52,7 @@ target_include_directories(argon2-gpu-common PRIVATE
 )
 
 if(CUDA_FOUND)
-    cuda_add_library(argon2-cuda SHARED
+    cuda_add_library(argon2-cuda STATIC
         lib/argon2-cuda/device.cpp
         lib/argon2-cuda/globalcontext.cpp
         lib/argon2-cuda/programcontext.cpp
@@ -52,7 +60,7 @@ if(CUDA_FOUND)
         lib/argon2-cuda/kernels.cu
     )
 else()
-    add_library(argon2-cuda SHARED
+    add_library(argon2-cuda STATIC
         lib/argon2-cuda/nocuda.cpp
     )
 endif()
@@ -67,7 +75,7 @@ target_include_directories(argon2-cuda INTERFACE
 )
 target_link_libraries(argon2-cuda argon2-gpu-common)
 
-add_library(argon2-opencl SHARED
+add_library(argon2-opencl STATIC
     lib/argon2-opencl/device.cpp
     lib/argon2-opencl/globalcontext.cpp
     lib/argon2-opencl/kernelloader.cpp
@@ -84,56 +92,5 @@ target_include_directories(argon2-opencl PRIVATE
     lib/argon2-opencl
 )
 target_link_libraries(argon2-opencl
-    argon2-gpu-common -lOpenCL
-)
-
-add_executable(argon2-gpu-test
-    src/argon2-gpu-test/main.cpp
-    src/argon2-gpu-test/testcase.cpp
-)
-target_include_directories(argon2-gpu-test PRIVATE src/argon2-gpu-test)
-target_link_libraries(argon2-gpu-test
-    argon2-cuda argon2-opencl argon2 -lOpenCL
-)
-
-add_executable(argon2-gpu-bench
-    src/argon2-gpu-bench/cpuexecutive.cpp
-    src/argon2-gpu-bench/cudaexecutive.cpp
-    src/argon2-gpu-bench/openclexecutive.cpp
-    src/argon2-gpu-bench/benchmark.cpp
-    src/argon2-gpu-bench/main.cpp
-)
-target_include_directories(argon2-gpu-bench PRIVATE src/argon2-gpu-bench)
-target_link_libraries(argon2-gpu-bench
-    argon2-cuda argon2-opencl argon2 -lOpenCL
-)
-
-add_test(argon2-gpu-test-opencl argon2-gpu-test -m opencl)
-add_test(argon2-gpu-test-cuda argon2-gpu-test -m cuda)
-
-install(
-    TARGETS argon2-gpu-common argon2-opencl argon2-cuda
-    DESTINATION ${LIBRARY_INSTALL_DIR}
-)
-install(FILES
-    include/argon2-gpu-common/argon2-common.h
-    include/argon2-gpu-common/argon2params.h
-    include/argon2-opencl/cl.hpp
-    include/argon2-opencl/opencl.h
-    include/argon2-opencl/device.h
-    include/argon2-opencl/globalcontext.h
-    include/argon2-opencl/programcontext.h
-    include/argon2-opencl/processingunit.h
-    include/argon2-opencl/kernelrunner.h
-    include/argon2-cuda/cudaexception.h
-    include/argon2-cuda/kernels.h
-    include/argon2-cuda/device.h
-    include/argon2-cuda/globalcontext.h
-    include/argon2-cuda/programcontext.h
-    include/argon2-cuda/processingunit.h
-    DESTINATION ${INCLUDE_INSTALL_DIR}
-)
-install(
-    TARGETS argon2-gpu-bench argon2-gpu-test
-    DESTINATION ${BINARY_INSTALL_DIR}
+    argon2-gpu-common ${OpenCL_LIBRARY}
 )
diff --git a/include/argon2-cuda/cudaexception.h b/include/argon2-cuda/cudaexception.h
index ebc8460..bc54d1d 100644
--- a/include/argon2-cuda/cudaexception.h
+++ b/include/argon2-cuda/cudaexception.h
@@ -6,6 +6,11 @@
 #endif
 
 #include <exception>
+#include <stdio.h>
+#ifndef __CUDACC__
+#include <boost/stacktrace.hpp>
+#endif
+#include <iostream>
 
 namespace argon2 {
 namespace cuda {
@@ -27,6 +32,14 @@ public:
     static void check(cudaError_t res)
     {
         if (res != cudaSuccess) {
+            printf("CUDA exception => |%s|\n", cudaGetErrorString(res));
+#ifndef __CUDACC__
+            std::cout << std::endl;
+            std::cout << "---- STACK TRACE ----" << std::endl;
+            std::cout << boost::stacktrace::stacktrace() << std::endl;
+#else
+            std::cout << "cannot show stack trace (.cu source)" << std::endl;
+#endif
             throw CudaException(res);
         }
     }
diff --git a/include/argon2-cuda/kernels.h b/include/argon2-cuda/kernels.h
index 16418b4..f6b47a8 100644
--- a/include/argon2-cuda/kernels.h
+++ b/include/argon2-cuda/kernels.h
@@ -26,6 +26,10 @@ private:
     cudaEvent_t start, end;
     cudaStream_t stream;
     void *memory;
+
+    void* memoryIn;
+    void* memoryOut;
+
     void *refs;
 
     void precomputeRefs();
@@ -53,6 +57,8 @@ public:
 
     void writeInputMemory(std::uint32_t jobId, const void *buffer);
     void readOutputMemory(std::uint32_t jobId, void *buffer);
+    void syncStream();
+    bool streamOperationsComplete();
 
     void run(std::uint32_t lanesPerBlock, std::uint32_t jobsPerBlock);
     float finish();
diff --git a/include/argon2-cuda/processingunit.h b/include/argon2-cuda/processingunit.h
index 2109154..44f9d2b 100644
--- a/include/argon2-cuda/processingunit.h
+++ b/include/argon2-cuda/processingunit.h
@@ -22,6 +22,7 @@ private:
     KernelRunner runner;
     std::uint32_t bestLanesPerBlock;
     std::uint32_t bestJobsPerBlock;
+    std::vector<uint8_t*> setPasswordBuffers;
 
 public:
     std::size_t getBatchSize() const { return runner.getBatchSize(); }
@@ -32,7 +33,11 @@ public:
             bool bySegment = true, bool precomputeRefs = false);
 
     void setPassword(std::size_t index, const void *pw, std::size_t pwSize);
-    void getHash(std::size_t index, void *hash);
+
+    void fetchResultAsync(std::size_t index, void *dest);
+    //void processResult(const void *src, void* dst);
+    void syncStream();
+    bool streamOperationsComplete();
 
     void beginProcessing();
     void endProcessing();
diff --git a/include/argon2-gpu-common/argon2-common.h b/include/argon2-gpu-common/argon2-common.h
index fbcf67c..7a849bb 100644
--- a/include/argon2-gpu-common/argon2-common.h
+++ b/include/argon2-gpu-common/argon2-common.h
@@ -1,6 +1,8 @@
 #ifndef ARGON2COMMON_H
 #define ARGON2COMMON_H
 
+#include <cstddef>
+
 namespace argon2 {
 
 enum {
diff --git a/include/argon2-opencl/cl.hpp b/include/argon2-opencl/cl.hpp
index ced34f5..1328b58 100644
--- a/include/argon2-opencl/cl.hpp
+++ b/include/argon2-opencl/cl.hpp
@@ -142,6 +142,12 @@
  * \endcode
  *
  */
+
+#define NOMINMAX
+#include <windows.h>
+#include <boost/stacktrace.hpp>
+#include <iostream>
+
 #ifndef CL_HPP_
 #define CL_HPP_
 
@@ -318,7 +324,6 @@ public:
 #define __ERR_STR(x) NULL
 #endif // __CL_ENABLE_EXCEPTIONS
 
-
 namespace detail
 {
 #if defined(__CL_ENABLE_EXCEPTIONS)
@@ -327,6 +332,11 @@ static inline cl_int errHandler (
     const char * errStr = NULL)
 {
     if (err != CL_SUCCESS) {
+        printf("OpenCL error: errCode=%d str=%s\n", err, errStr ? errStr: "none");
+
+        std::cout << std::endl;
+        std::cout << "---- STACK TRACE ----" << std::endl;
+        std::cout << boost::stacktrace::stacktrace() << std::endl;
         throw Error(err, errStr);
     }
     return err;
diff --git a/include/argon2-opencl/kernelrunner.h b/include/argon2-opencl/kernelrunner.h
index a1bba8b..ed2f08d 100644
--- a/include/argon2-opencl/kernelrunner.h
+++ b/include/argon2-opencl/kernelrunner.h
@@ -22,6 +22,9 @@ private:
     cl::Buffer memoryBuffer, refsBuffer;
     cl::Event start, end;
 
+    cl::Event upload;
+    cl::Event download;
+
     std::size_t memorySize;
 
     void precomputeRefs();
@@ -42,11 +45,13 @@ public:
                  const Argon2Params *params, const Device *device,
                  std::uint32_t batchSize, bool bySegment, bool precompute);
 
-    void *mapInputMemory(std::uint32_t jobId);
-    void unmapInputMemory(void *memory);
+//    void *mapInputMemory(std::uint32_t jobId);
+//    void unmapInputMemory(void *memory);
+    void uploadToInputMemoryAsync(std::uint32_t jobId, const void* srcPtr);
+    void fetchOutputMemoryAsync(std::uint32_t jobId, void* dstPtr);
 
-    void *mapOutputMemory(std::uint32_t jobId);
-    void unmapOutputMemory(void *memory);
+    //void *mapOutputMemory(std::uint32_t jobId);
+    //void unmapOutputMemory(void *memory);
 
     void run(std::uint32_t lanesPerBlock, std::uint32_t jobsPerBlock);
     float finish();
diff --git a/include/argon2-opencl/processingunit.h b/include/argon2-opencl/processingunit.h
index 277272d..52e6a76 100644
--- a/include/argon2-opencl/processingunit.h
+++ b/include/argon2-opencl/processingunit.h
@@ -18,6 +18,7 @@ private:
     KernelRunner runner;
     std::uint32_t bestLanesPerBlock;
     std::uint32_t bestJobsPerBlock;
+    std::vector<uint8_t*> setPasswordBuffers;
 
 public:
     std::size_t getBatchSize() const { return runner.getBatchSize(); }
@@ -28,7 +29,9 @@ public:
             bool bySegment = true, bool precomputeRefs = false);
 
     void setPassword(std::size_t index, const void *pw, std::size_t pwSize);
-    void getHash(std::size_t index, void *hash);
+    //void getHash(std::size_t index, void *hash);
+
+    void fetchResultAsync(std::size_t index, void *dest);
 
     void beginProcessing();
     void endProcessing();
diff --git a/lib/argon2-cuda/kernels.cu b/lib/argon2-cuda/kernels.cu
index 79fb767..84d1dc7 100644
--- a/lib/argon2-cuda/kernels.cu
+++ b/lib/argon2-cuda/kernels.cu
@@ -3,9 +3,14 @@
 #define __CUDACC__
 #endif
 
+#define NO_PAGEFILE_ALLOC
+
 #include "kernels.h"
 #include "cudaexception.h"
 
+#include <iostream>
+#include <iomanip>
+
 #include <stdexcept>
 #ifndef NDEBUG
 #include <iostream>
@@ -25,6 +30,10 @@
 #define THREADS_PER_LANE 32
 #define QWORDS_PER_THREAD (ARGON2_QWORDS_IN_BLOCK / 32)
 
+#define MEMORY_IN_SIZE (2048)
+#define MEMORY_OUT_SIZE (1024)
+#define MEMORY_OUT_OFFSET (536869888)
+
 namespace argon2 {
 namespace cuda {
 
@@ -49,8 +58,8 @@ __device__ uint64_t u64_shuffle(uint64_t v, uint32_t thread)
 {
     uint32_t lo = u64_lo(v);
     uint32_t hi = u64_hi(v);
-    lo = __shfl(lo, thread);
-    hi = __shfl(hi, thread);
+    lo = __shfl_sync(0xFFFFFFFF, lo, thread);
+    hi = __shfl_sync(0xFFFFFFFF, hi, thread);
     return u64_build(hi, lo);
 }
 
@@ -670,14 +679,59 @@ __global__ void argon2_kernel_segment(
 template<uint32_t type, uint32_t version>
 __global__ void argon2_kernel_oneshot(
         struct block_g *memory, uint32_t passes, uint32_t lanes,
-        uint32_t segment_blocks)
+        uint32_t segment_blocks,
+        void* memIn, void* memOut)
 {
     uint32_t job_id = blockIdx.z * blockDim.z + threadIdx.z;
-    uint32_t lane   = threadIdx.y;
+    uint32_t lane = threadIdx.y;
     uint32_t thread = threadIdx.x;
-
     uint32_t lane_blocks = ARGON2_SYNC_POINTS * segment_blocks;
 
+#ifdef NO_PAGEFILE_ALLOC // job_id==0 in this case
+    __shared__ uint8_t* data;
+
+    const size_t MEM_SIZE = 512 * 1024 * 1024;
+
+    // -- allocate device side working memory --
+    // The first thread in the block does the allocation and then
+    // shares the pointer with all other threads through shared memory,
+    // so that access can easily be coalesced.
+    if (threadIdx.x == 0) {
+        data = (uint8_t*)malloc(MEM_SIZE);
+    }
+    __syncthreads();
+
+    if (data == NULL) {
+        return;
+    }
+    // -- copy input data inside --
+    if (threadIdx.x == 0) {
+        memcpy(data, memIn, MEMORY_IN_SIZE);
+    }
+    
+    // Check for failure
+#if 0
+    if (threadIdx.x == 0) {
+        if (data == NULL) {
+            ((uint8_t*)memOut)[0] = 66;
+            return;
+        }
+        else {
+            ((uint8_t*)memOut)[0] = 33;
+            free(data);
+            return;
+        }
+    }
+    else {
+        return;
+    }
+#endif
+
+    __syncthreads();
+
+    memory = (argon2::cuda::block_g*)data;
+#endif
+
     /* select job's memory region: */
     memory += (size_t)job_id * lanes * lane_blocks;
 
@@ -755,6 +809,18 @@ __global__ void argon2_kernel_oneshot(
         }
         mem_curr = mem_lane;
     }
+
+#ifdef NO_PAGEFILE_ALLOC
+    // Ensure all threads complete before freeing 
+    __syncthreads();
+
+    // Only one thread may free the memory!
+    if (threadIdx.x == 0) {
+        // copy result to output mem
+        memcpy(memOut, data + MEMORY_OUT_OFFSET, MEMORY_OUT_SIZE);
+        free(data);
+    }
+#endif
 }
 
 KernelRunner::KernelRunner(uint32_t type, uint32_t version, uint32_t passes,
@@ -763,42 +829,55 @@ KernelRunner::KernelRunner(uint32_t type, uint32_t version, uint32_t passes,
     : type(type), version(version), passes(passes), lanes(lanes),
       segmentBlocks(segmentBlocks), batchSize(batchSize), bySegment(bySegment),
       precompute(precompute), stream(nullptr), memory(nullptr),
-      refs(nullptr), start(nullptr), end(nullptr)
+      refs(nullptr), start(nullptr), end(nullptr),
+      memoryIn(nullptr), memoryOut(nullptr)
 {
     // FIXME: check overflow:
     size_t memorySize = static_cast<size_t>(lanes) * segmentBlocks
             * ARGON2_SYNC_POINTS * ARGON2_BLOCK_SIZE * batchSize;
 
-#ifndef NDEBUG
-        std::cerr << "[INFO] Allocating " << memorySize << " bytes for memory..."
+//#ifndef NDEBUG
+        std::cerr << "[INFO] Allocating " << std::fixed << std::setprecision(2) << (memorySize/(1024.f*1024.f*1024.f)) << " GB for Miner memory..."
                   << std::endl;
-#endif
-
-    CudaException::check(cudaMalloc(&memory, memorySize));
-
-    CudaException::check(cudaEventCreate(&start));
-    CudaException::check(cudaEventCreate(&end));
+//#endif
 
-    CudaException::check(cudaStreamCreate(&stream));
-
-    if ((type == ARGON2_I || type == ARGON2_ID) && precompute) {
-        uint32_t segments =
-                type == ARGON2_ID
-                ? lanes * (ARGON2_SYNC_POINTS / 2)
-                : passes * lanes * ARGON2_SYNC_POINTS;
+#ifdef NO_PAGEFILE_ALLOC
+    CudaException::check(cudaDeviceSetLimit(cudaLimitMallocHeapSize, (512*5) * 1024 * 1024));
+    
+    //size_t checkSize = 0;
+    //CudaException::check(cudaThreadGetLimit(&checkSize, cudaLimitMallocHeapSize));
 
-        size_t refsSize = segments * segmentBlocks * sizeof(struct ref);
+    CudaException::check(cudaMalloc(&memoryIn, MEMORY_IN_SIZE));
+    CudaException::check(cudaMalloc(&memoryOut, MEMORY_OUT_SIZE + 1));
 
-#ifndef NDEBUG
-        std::cerr << "[INFO] Allocating " << refsSize << " bytes for refs..."
-                  << std::endl;
+    std::cout << "----------- NO_PAGEFILE_ALLOC -------------" << std::endl;
+#else
+    std::cout << "----------- PAGEFILE_ALLOC size = " << memorySize << " -------------" << std::endl;
+    CudaException::check(cudaMalloc(&memory, memorySize));
 #endif
+//  CudaException::check(cudaEventCreate(&start));
+//  CudaException::check(cudaEventCreate(&end));
 
-        CudaException::check(cudaMalloc(&refs, refsSize));
+    CudaException::check(cudaStreamCreate(&stream));
 
-        precomputeRefs();
-        CudaException::check(cudaStreamSynchronize(stream));
-    }
+//    if ((type == ARGON2_I || type == ARGON2_ID) && precompute) {
+//        uint32_t segments =
+//                type == ARGON2_ID
+//                ? lanes * (ARGON2_SYNC_POINTS / 2)
+//                : passes * lanes * ARGON2_SYNC_POINTS;
+//
+//        size_t refsSize = segments * segmentBlocks * sizeof(struct ref);
+//
+//#ifndef NDEBUG
+//        std::cerr << "[INFO] Allocating " << refsSize << " bytes for refs..."
+//                  << std::endl;
+//#endif
+//
+//        CudaException::check(cudaMalloc(&refs, refsSize));
+//
+//        precomputeRefs();
+//        CudaException::check(cudaStreamSynchronize(stream));
+//    }
 }
 
 void KernelRunner::precomputeRefs()
@@ -828,12 +907,12 @@ void KernelRunner::precomputeRefs()
 
 KernelRunner::~KernelRunner()
 {
-    if (start != nullptr) {
-        cudaEventDestroy(start);
-    }
-    if (end != nullptr) {
-        cudaEventDestroy(end);
-    }
+    //if (start != nullptr) {
+    //    cudaEventDestroy(start);
+    //}
+    //if (end != nullptr) {
+    //    cudaEventDestroy(end);
+    //}
     if (stream != nullptr) {
         cudaStreamDestroy(stream);
     }
@@ -845,28 +924,72 @@ KernelRunner::~KernelRunner()
     }
 }
 
+void KernelRunner::syncStream() {
+    CudaException::check(cudaStreamSynchronize(stream));
+}
+
+bool KernelRunner::streamOperationsComplete() {
+    cudaError_t res = cudaStreamQuery(stream);
+    if (res == cudaSuccess) {
+        return true;
+    }
+    else if (res == cudaErrorNotReady) {
+        return false;
+    }
+    else {
+        CudaException::check(res);
+        return false;
+    }
+}
+
 void KernelRunner::writeInputMemory(uint32_t jobId, const void *buffer)
 {
+#ifdef NO_PAGEFILE_ALLOC
+    if (jobId != 0) {
+        exit(1);
+    }
+#endif
+
     std::size_t memorySize = static_cast<size_t>(lanes) * segmentBlocks
-            * ARGON2_SYNC_POINTS * ARGON2_BLOCK_SIZE;
+        * ARGON2_SYNC_POINTS * ARGON2_BLOCK_SIZE;
     std::size_t size = static_cast<size_t>(lanes) * 2 * ARGON2_BLOCK_SIZE;
     std::size_t offset = memorySize * jobId;
+
+#ifdef NO_PAGEFILE_ALLOC
+    CudaException::check(cudaMemcpyAsync(memoryIn, buffer, MEMORY_IN_SIZE, cudaMemcpyHostToDevice, stream));
+#else
+    // -- normal
     auto mem = static_cast<uint8_t *>(memory) + offset;
-    CudaException::check(cudaMemcpyAsync(mem, buffer, size,
-                                         cudaMemcpyHostToDevice, stream));
-    CudaException::check(cudaStreamSynchronize(stream));
+    CudaException::check(cudaMemcpyAsync(mem, buffer, size, cudaMemcpyHostToDevice, stream));
+    //CudaException::check(cudaStreamSynchronize(stream));
+#endif
 }
 
 void KernelRunner::readOutputMemory(uint32_t jobId, void *buffer)
 {
+#ifdef NO_PAGEFILE_ALLOC
+    CudaException::check(cudaMemcpyAsync(buffer, memoryOut, 
+                                         MEMORY_OUT_SIZE, cudaMemcpyDeviceToHost, stream));
+
+    /*if ((int)(((uint8_t*)buffer)[0]) != 33) {
+        std::cout << "malloc fail ..." << std::endl;
+    }*/
+    //std::cout << "memout[0] = " << (int)(((uint8_t*)buffer)[0]) << std::endl;
+#else
     std::size_t memorySize = static_cast<size_t>(lanes) * segmentBlocks
             * ARGON2_SYNC_POINTS * ARGON2_BLOCK_SIZE;
     std::size_t size = static_cast<size_t>(lanes) * ARGON2_BLOCK_SIZE;
     std::size_t offset = memorySize * (jobId + 1) - size;
     auto mem = static_cast<uint8_t *>(memory) + offset;
+
+    //std::cout <<
+    //    "offset = " << offset <<
+    //    ", size = " << size << std::endl;
+
     CudaException::check(cudaMemcpyAsync(buffer, mem, size,
                                          cudaMemcpyDeviceToHost, stream));
-    CudaException::check(cudaStreamSynchronize(stream));
+//    CudaException::check(cudaStreamSynchronize(stream));
+#endif
 }
 
 void KernelRunner::runKernelSegment(uint32_t lanesPerBlock,
@@ -967,6 +1090,11 @@ void KernelRunner::runKernelOneshot(uint32_t lanesPerBlock,
     struct block_g *memory_blocks = (struct block_g *)memory;
     dim3 blocks = dim3(1, 1, batchSize / jobsPerBlock);
     dim3 threads = dim3(THREADS_PER_LANE, lanes, jobsPerBlock);
+
+    //std::cout << "runKernelOneshot: " <<
+    //    "blocks=" << blocks.x << "," << blocks.y << "," << blocks.z <<
+    //    "threads=" << threads.x << "," << threads.y << "," << threads.z << std::endl;
+
     if (type == ARGON2_I) {
         if (precompute) {
             struct ref *refs = (struct ref *)this->refs;
@@ -983,11 +1111,11 @@ void KernelRunner::runKernelOneshot(uint32_t lanesPerBlock,
             if (version == ARGON2_VERSION_10) {
                 argon2_kernel_oneshot<ARGON2_I, ARGON2_VERSION_10>
                         <<<blocks, threads, 0, stream>>>(
-                            memory_blocks, passes, lanes, segmentBlocks);
+                            memory_blocks, passes, lanes, segmentBlocks, memoryIn, memoryOut);
             } else {
                 argon2_kernel_oneshot<ARGON2_I, ARGON2_VERSION_13>
                         <<<blocks, threads, 0, stream>>>(
-                            memory_blocks, passes, lanes, segmentBlocks);
+                            memory_blocks, passes, lanes, segmentBlocks, memoryIn, memoryOut);
             }
         }
     } else if (type == ARGON2_ID) {
@@ -1006,29 +1134,29 @@ void KernelRunner::runKernelOneshot(uint32_t lanesPerBlock,
             if (version == ARGON2_VERSION_10) {
                 argon2_kernel_oneshot<ARGON2_ID, ARGON2_VERSION_10>
                         <<<blocks, threads, 0, stream>>>(
-                            memory_blocks, passes, lanes, segmentBlocks);
+                            memory_blocks, passes, lanes, segmentBlocks, memoryIn, memoryOut);
             } else {
                 argon2_kernel_oneshot<ARGON2_ID, ARGON2_VERSION_13>
                         <<<blocks, threads, 0, stream>>>(
-                            memory_blocks, passes, lanes, segmentBlocks);
+                            memory_blocks, passes, lanes, segmentBlocks, memoryIn, memoryOut);
             }
         }
     } else {
         if (version == ARGON2_VERSION_10) {
             argon2_kernel_oneshot<ARGON2_D, ARGON2_VERSION_10>
                     <<<blocks, threads, 0, stream>>>(
-                        memory_blocks, passes, lanes, segmentBlocks);
+                        memory_blocks, passes, lanes, segmentBlocks, memoryIn, memoryOut);
         } else {
             argon2_kernel_oneshot<ARGON2_D, ARGON2_VERSION_13>
                     <<<blocks, threads, 0, stream>>>(
-                        memory_blocks, passes, lanes, segmentBlocks);
+                        memory_blocks, passes, lanes, segmentBlocks, memoryIn, memoryOut);
         }
     }
 }
 
 void KernelRunner::run(uint32_t lanesPerBlock, uint32_t jobsPerBlock)
 {
-    CudaException::check(cudaEventRecord(start, stream));
+    //CudaException::check(cudaEventRecord(start, stream));
 
     if (bySegment) {
         for (uint32_t pass = 0; pass < passes; pass++) {
@@ -1042,15 +1170,15 @@ void KernelRunner::run(uint32_t lanesPerBlock, uint32_t jobsPerBlock)
 
     CudaException::check(cudaGetLastError());
 
-    CudaException::check(cudaEventRecord(end, stream));
+    //CudaException::check(cudaEventRecord(end, stream));
 }
 
 float KernelRunner::finish()
 {
-    CudaException::check(cudaStreamSynchronize(stream));
+    //CudaException::check(cudaStreamSynchronize(stream));
 
     float time = 0.0;
-    CudaException::check(cudaEventElapsedTime(&time, start, end));
+    //CudaException::check(cudaEventElapsedTime(&time, start, end));
     return time;
 }
 
diff --git a/lib/argon2-cuda/processingunit.cpp b/lib/argon2-cuda/processingunit.cpp
index 7768427..5be62a2 100644
--- a/lib/argon2-cuda/processingunit.cpp
+++ b/lib/argon2-cuda/processingunit.cpp
@@ -24,6 +24,9 @@ static bool isPowerOfTwo(std::uint32_t x)
     return (x & (x - 1)) == 0;
 }
 
+#pragma warning(disable:4267)
+#pragma warning(disable:4101)
+
 ProcessingUnit::ProcessingUnit(
         const ProgramContext *programContext, const Argon2Params *params,
         const Device *device, std::size_t batchSize, bool bySegment,
@@ -36,13 +39,27 @@ ProcessingUnit::ProcessingUnit(
       bestLanesPerBlock(runner.getMinLanesPerBlock()),
       bestJobsPerBlock(runner.getMinJobsPerBlock())
 {
+    // already done by caller, but let's still do it again just in case ...
+    // (it is done by the caller because the runner constructor also needs current device set !)
     setCudaDevice(device->getDeviceIndex());
 
-    /* pre-fill first blocks with pseudo-random data: */
-    for (std::size_t i = 0; i < batchSize; i++) {
-        setPassword(i, NULL, 0);
+    // preallocate buffers used by ProcessingUnit::setPassword
+    std::size_t size = params->getLanes() * 2 * ARGON2_BLOCK_SIZE;
+    for (int i = 0; i < batchSize; i++) {
+        uint8_t* ptrPinnedMem = nullptr;
+        cudaError_t status = cudaMallocHost((void**)&(ptrPinnedMem), size);
+        if (status != cudaSuccess) {
+            std::cout << "Error allocating pinned host memory" << std::endl;
+            exit(1);
+        }
+        setPasswordBuffers.push_back(ptrPinnedMem);
     }
 
+    /* pre-fill first blocks with pseudo-random data: */
+    //for (std::size_t i = 0; i < batchSize; i++) {
+    //    setPassword(i, NULL, 0);
+    //}
+
     if (runner.getMaxLanesPerBlock() > runner.getMinLanesPerBlock()
             && isPowerOfTwo(runner.getMaxLanesPerBlock())) {
 #ifndef NDEBUG
@@ -125,24 +142,36 @@ ProcessingUnit::ProcessingUnit(
 void ProcessingUnit::setPassword(std::size_t index, const void *pw,
                                  std::size_t pwSize)
 {
-    std::size_t size = params->getLanes() * 2 * ARGON2_BLOCK_SIZE;
-    auto buffer = std::unique_ptr<uint8_t[]>(new uint8_t[size]);
-    params->fillFirstBlocks(buffer.get(), pw, pwSize,
+    //std::size_t size = params->getLanes() * 2 * ARGON2_BLOCK_SIZE;
+    //auto buffer = std::unique_ptr<uint8_t[]>(new uint8_t[size]);
+
+    params->fillFirstBlocks(setPasswordBuffers[index], pw, pwSize,
                             programContext->getArgon2Type(),
                             programContext->getArgon2Version());
-    runner.writeInputMemory(index, buffer.get());
+
+    runner.writeInputMemory(index, setPasswordBuffers[index]);
 }
 
-void ProcessingUnit::getHash(std::size_t index, void *hash)
-{
+void ProcessingUnit::fetchResultAsync(std::size_t index, void *dest) {
     std::size_t size = params->getLanes() * ARGON2_BLOCK_SIZE;
-    auto buffer = std::unique_ptr<uint8_t[]>(new uint8_t[size]);
-    runner.readOutputMemory(index, buffer.get());
-    params->finalize(hash, buffer.get());
+    runner.readOutputMemory(index, dest);
+}
+
+//void ProcessingUnit::processResult(const void *src, void* dst) {
+//    params->finalize(dst, src);
+//}
+
+void ProcessingUnit::syncStream() {
+    runner.syncStream();
+}
+
+bool ProcessingUnit::streamOperationsComplete() {
+    return runner.streamOperationsComplete();
 }
 
 void ProcessingUnit::beginProcessing()
 {
+    // we MUST set cuda device before launching a kernel
     setCudaDevice(device->getDeviceIndex());
     runner.run(bestLanesPerBlock, bestJobsPerBlock);
 }
diff --git a/lib/argon2-gpu-common/argon2params.cpp b/lib/argon2-gpu-common/argon2params.cpp
index dd122d8..b74c11d 100644
--- a/lib/argon2-gpu-common/argon2params.cpp
+++ b/lib/argon2-gpu-common/argon2params.cpp
@@ -20,6 +20,8 @@ static void store32(void *dst, std::uint32_t v)
     *out++ = static_cast<std::uint8_t>(v);
 }
 
+#pragma warning(disable:4267)
+
 Argon2Params::Argon2Params(
         std::size_t outLen,
         const void *salt, std::size_t saltLen,
diff --git a/lib/argon2-gpu-common/blake2b.h b/lib/argon2-gpu-common/blake2b.h
index 094fb83..7f438ee 100644
--- a/lib/argon2-gpu-common/blake2b.h
+++ b/lib/argon2-gpu-common/blake2b.h
@@ -2,6 +2,7 @@
 #define ARGON2_BLAKE2B_H
 
 #include <cstdint>
+#include <cstddef>
 
 namespace argon2 {
 
diff --git a/lib/argon2-opencl/kernelloader.cpp b/lib/argon2-opencl/kernelloader.cpp
index 22949f3..927a44d 100644
--- a/lib/argon2-opencl/kernelloader.cpp
+++ b/lib/argon2-opencl/kernelloader.cpp
@@ -38,6 +38,7 @@ cl::Program KernelLoader::loadArgon2Program(
         for (cl::Device &device : context.getInfo<CL_CONTEXT_DEVICES>()) {
             std::cerr << "  Build log from device '" << device.getInfo<CL_DEVICE_NAME>() << "':" << std::endl;
             std::cerr << prog.getBuildInfo<CL_PROGRAM_BUILD_LOG>(device);
+			err;
         }
         throw;
     }
diff --git a/lib/argon2-opencl/kernelrunner.cpp b/lib/argon2-opencl/kernelrunner.cpp
index 9fe39b4..ccd75bb 100644
--- a/lib/argon2-opencl/kernelrunner.cpp
+++ b/lib/argon2-opencl/kernelrunner.cpp
@@ -1,6 +1,7 @@
 #include "kernelrunner.h"
 
 #include <stdexcept>
+#include <thread>
 
 #ifndef NDEBUG
 #include <iostream>
@@ -110,34 +111,83 @@ void KernelRunner::precomputeRefs()
     queue.finish();
 }
 
-void *KernelRunner::mapInputMemory(std::uint32_t jobId)
-{
+void KernelRunner::uploadToInputMemoryAsync(std::uint32_t jobId, const void* srcPtr) {
     std::size_t memorySize = params->getMemorySize();
     std::size_t mappedSize = params->getLanes() * 2 * ARGON2_BLOCK_SIZE;
-    return queue.enqueueMapBuffer(memoryBuffer, true, CL_MAP_WRITE,
-                                  memorySize * jobId, mappedSize);
-}
 
-void KernelRunner::unmapInputMemory(void *memory)
-{
-    queue.enqueueUnmapMemObject(memoryBuffer, memory);
+    bool blocking = false; // true;
+    size_t offset = memorySize * jobId;
+    size_t size = mappedSize;
+
+    cl_int res = queue.enqueueWriteBuffer(
+        memoryBuffer,
+        blocking,
+        offset,
+        size,
+        srcPtr,
+        NULL,
+        &upload);
+
+    //queue.flush();
+    //while (1) {
+    //    auto status = upload.getInfo<CL_EVENT_COMMAND_EXECUTION_STATUS>();
+    //    if (status == CL_COMPLETE) {
+    //        //printf("yo\n");
+    //        break;
+    //    }
+    //    else {
+    //        //printf("wait status=%d\n", status);
+    //        std::this_thread::sleep_for(std::chrono::milliseconds(5));
+    //    }
+    //}
 }
 
-void *KernelRunner::mapOutputMemory(std::uint32_t jobId)
-{
+//void *KernelRunner::mapInputMemory(std::uint32_t jobId)
+//{
+//    std::size_t memorySize = params->getMemorySize();
+//    std::size_t mappedSize = params->getLanes() * 2 * ARGON2_BLOCK_SIZE;
+//    return queue.enqueueMapBuffer(memoryBuffer, true, CL_MAP_WRITE,
+//                                  memorySize * jobId, mappedSize);
+//}
+//
+//void KernelRunner::unmapInputMemory(void *memory)
+//{
+//    queue.enqueueUnmapMemObject(memoryBuffer, memory);
+//}
+
+void KernelRunner::fetchOutputMemoryAsync(std::uint32_t jobId, void* dstPtr) {
     std::size_t memorySize = params->getMemorySize();
-    std::size_t mappedSize = static_cast<std::size_t>(params->getLanes())
-            * ARGON2_BLOCK_SIZE;
+    std::size_t mappedSize = static_cast<std::size_t>(params->getLanes()) * ARGON2_BLOCK_SIZE;
     std::size_t mappedOffset = memorySize * (jobId + 1) - mappedSize;
-    return queue.enqueueMapBuffer(memoryBuffer, true, CL_MAP_READ,
-                                  mappedOffset, mappedSize);
-}
 
-void KernelRunner::unmapOutputMemory(void *memory)
-{
-    queue.enqueueUnmapMemObject(memoryBuffer, memory);
+    bool blocking = false; // true;
+
+    cl_int res = queue.enqueueReadBuffer(
+        memoryBuffer,
+        blocking,
+        mappedOffset,
+        mappedSize,
+        dstPtr,
+        NULL,
+        &download);
+
+    //download.wait();
 }
 
+//void *KernelRunner::mapOutputMemory(std::uint32_t jobId)
+//{
+//    std::size_t memorySize = params->getMemorySize();
+//    std::size_t mappedSize = static_cast<std::size_t>(params->getLanes()) * ARGON2_BLOCK_SIZE;
+//    std::size_t mappedOffset = memorySize * (jobId + 1) - mappedSize;
+//    return queue.enqueueMapBuffer(memoryBuffer, true, CL_MAP_READ,
+//                                  mappedOffset, mappedSize);
+//}
+//
+//void KernelRunner::unmapOutputMemory(void *memory)
+//{
+//    queue.enqueueUnmapMemObject(memoryBuffer, memory);
+//}
+
 void KernelRunner::run(std::uint32_t lanesPerBlock, std::uint32_t jobsPerBlock)
 {
     std::uint32_t lanes = params->getLanes();
@@ -184,7 +234,20 @@ void KernelRunner::run(std::uint32_t lanesPerBlock, std::uint32_t jobsPerBlock)
 
 float KernelRunner::finish()
 {
-    end.wait();
+    queue.flush();
+    while (1) {
+        auto status = end.getInfo<CL_EVENT_COMMAND_EXECUTION_STATUS>();
+        if (status == CL_COMPLETE) {
+            printf("yo\n");
+            break;
+        }
+        else {
+            printf("wait status=%d\n", status);
+            std::this_thread::sleep_for(std::chrono::milliseconds(5));
+        }
+    }
+
+   // end.wait();
 
     cl_ulong nsStart = start.getProfilingInfo<CL_PROFILING_COMMAND_END>();
     cl_ulong nsEnd   = end.getProfilingInfo<CL_PROFILING_COMMAND_END>();
diff --git a/lib/argon2-opencl/processingunit.cpp b/lib/argon2-opencl/processingunit.cpp
index 598ced7..1ef6175 100644
--- a/lib/argon2-opencl/processingunit.cpp
+++ b/lib/argon2-opencl/processingunit.cpp
@@ -13,6 +13,9 @@ static bool isPowerOfTwo(std::uint32_t x)
     return (x & (x - 1)) == 0;
 }
 
+#pragma warning(disable:4267)
+#pragma warning(disable:4101)
+
 ProcessingUnit::ProcessingUnit(
         const ProgramContext *programContext, const Argon2Params *params,
         const Device *device, std::size_t batchSize,
@@ -23,6 +26,13 @@ ProcessingUnit::ProcessingUnit(
       bestLanesPerBlock(runner.getMinLanesPerBlock()),
       bestJobsPerBlock(runner.getMinJobsPerBlock())
 {
+    // preallocate buffers used by ProcessingUnit::setPassword
+    std::size_t size = params->getLanes() * 2 * ARGON2_BLOCK_SIZE;
+    for (int i = 0; i < batchSize; i++) {
+        uint8_t* ptrPinnedMem = new uint8_t[size];
+        setPasswordBuffers.push_back(ptrPinnedMem);
+    }
+
     /* pre-fill first blocks with pseudo-random data: */
     for (std::size_t i = 0; i < batchSize; i++) {
         setPassword(i, NULL, 0);
@@ -110,20 +120,28 @@ ProcessingUnit::ProcessingUnit(
 void ProcessingUnit::setPassword(std::size_t index, const void *pw,
                                  std::size_t pwSize)
 {
-    void *memory = runner.mapInputMemory(index);
-    params->fillFirstBlocks(memory, pw, pwSize,
+    params->fillFirstBlocks(setPasswordBuffers[index], pw, pwSize,
                             programContext->getArgon2Type(),
                             programContext->getArgon2Version());
-    runner.unmapInputMemory(memory);
+
+    runner.uploadToInputMemoryAsync(index, setPasswordBuffers[index]);
+
+    //void *memory = runner.mapInputMemory(index);
+    // ...
+    //runner.unmapInputMemory(memory);
 }
 
-void ProcessingUnit::getHash(std::size_t index, void *hash)
-{
-    void *memory = runner.mapOutputMemory(index);
-    params->finalize(hash, memory);
-    runner.unmapOutputMemory(memory);
+void ProcessingUnit::fetchResultAsync(std::size_t index, void *dest) {
+    runner.fetchOutputMemoryAsync(index, dest);
 }
 
+//void ProcessingUnit::getHash(std::size_t index, void *hash)
+//{
+//    void *memory = runner.mapOutputMemory(index);
+//    params->finalize(hash, memory);
+//    runner.unmapOutputMemory(memory);
+//}
+
 void ProcessingUnit::beginProcessing()
 {
     runner.run(bestLanesPerBlock, bestJobsPerBlock);
