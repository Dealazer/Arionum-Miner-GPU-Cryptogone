diff --git a/CMakeLists.txt b/CMakeLists.txt
index 3dd95ba..15fb786 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -28,9 +28,17 @@ if(CUDA_FOUND)
     )
 endif()
 
+FIND_PACKAGE(OpenCL)
+INCLUDE_DIRECTORIES(${OPENCL_INCLUDE_DIR})
+if (OPENCL_FOUND)
+    message("INFO: Using OPENCL version ${OpenCL_VERSION_MAJOR}.${OpenCL_VERSION_MINOR}")
+else()
+    message("INFO: OPENCL not found")
+endif()
+
 add_subdirectory(ext/argon2)
 
-add_library(argon2-gpu-common SHARED
+add_library(argon2-gpu-common STATIC
     lib/argon2-gpu-common/argon2params.cpp
     lib/argon2-gpu-common/blake2b.cpp
 )
@@ -44,7 +52,7 @@ target_include_directories(argon2-gpu-common PRIVATE
 )
 
 if(CUDA_FOUND)
-    cuda_add_library(argon2-cuda SHARED
+    cuda_add_library(argon2-cuda STATIC
         lib/argon2-cuda/device.cpp
         lib/argon2-cuda/globalcontext.cpp
         lib/argon2-cuda/programcontext.cpp
@@ -52,7 +60,7 @@ if(CUDA_FOUND)
         lib/argon2-cuda/kernels.cu
     )
 else()
-    add_library(argon2-cuda SHARED
+    add_library(argon2-cuda STATIC
         lib/argon2-cuda/nocuda.cpp
     )
 endif()
@@ -67,7 +75,7 @@ target_include_directories(argon2-cuda INTERFACE
 )
 target_link_libraries(argon2-cuda argon2-gpu-common)
 
-add_library(argon2-opencl SHARED
+add_library(argon2-opencl STATIC
     lib/argon2-opencl/device.cpp
     lib/argon2-opencl/globalcontext.cpp
     lib/argon2-opencl/kernelloader.cpp
@@ -84,56 +92,5 @@ target_include_directories(argon2-opencl PRIVATE
     lib/argon2-opencl
 )
 target_link_libraries(argon2-opencl
-    argon2-gpu-common -lOpenCL
-)
-
-add_executable(argon2-gpu-test
-    src/argon2-gpu-test/main.cpp
-    src/argon2-gpu-test/testcase.cpp
-)
-target_include_directories(argon2-gpu-test PRIVATE src/argon2-gpu-test)
-target_link_libraries(argon2-gpu-test
-    argon2-cuda argon2-opencl argon2 -lOpenCL
-)
-
-add_executable(argon2-gpu-bench
-    src/argon2-gpu-bench/cpuexecutive.cpp
-    src/argon2-gpu-bench/cudaexecutive.cpp
-    src/argon2-gpu-bench/openclexecutive.cpp
-    src/argon2-gpu-bench/benchmark.cpp
-    src/argon2-gpu-bench/main.cpp
-)
-target_include_directories(argon2-gpu-bench PRIVATE src/argon2-gpu-bench)
-target_link_libraries(argon2-gpu-bench
-    argon2-cuda argon2-opencl argon2 -lOpenCL
-)
-
-add_test(argon2-gpu-test-opencl argon2-gpu-test -m opencl)
-add_test(argon2-gpu-test-cuda argon2-gpu-test -m cuda)
-
-install(
-    TARGETS argon2-gpu-common argon2-opencl argon2-cuda
-    DESTINATION ${LIBRARY_INSTALL_DIR}
-)
-install(FILES
-    include/argon2-gpu-common/argon2-common.h
-    include/argon2-gpu-common/argon2params.h
-    include/argon2-opencl/cl.hpp
-    include/argon2-opencl/opencl.h
-    include/argon2-opencl/device.h
-    include/argon2-opencl/globalcontext.h
-    include/argon2-opencl/programcontext.h
-    include/argon2-opencl/processingunit.h
-    include/argon2-opencl/kernelrunner.h
-    include/argon2-cuda/cudaexception.h
-    include/argon2-cuda/kernels.h
-    include/argon2-cuda/device.h
-    include/argon2-cuda/globalcontext.h
-    include/argon2-cuda/programcontext.h
-    include/argon2-cuda/processingunit.h
-    DESTINATION ${INCLUDE_INSTALL_DIR}
-)
-install(
-    TARGETS argon2-gpu-bench argon2-gpu-test
-    DESTINATION ${BINARY_INSTALL_DIR}
+    argon2-gpu-common ${OpenCL_LIBRARY}
 )
diff --git a/include/argon2-cuda/cudaexception.h b/include/argon2-cuda/cudaexception.h
index ebc8460..bc54d1d 100644
--- a/include/argon2-cuda/cudaexception.h
+++ b/include/argon2-cuda/cudaexception.h
@@ -6,6 +6,11 @@
 #endif
 
 #include <exception>
+#include <stdio.h>
+#ifndef __CUDACC__
+#include <boost/stacktrace.hpp>
+#endif
+#include <iostream>
 
 namespace argon2 {
 namespace cuda {
@@ -27,6 +32,14 @@ public:
     static void check(cudaError_t res)
     {
         if (res != cudaSuccess) {
+            printf("CUDA exception => |%s|\n", cudaGetErrorString(res));
+#ifndef __CUDACC__
+            std::cout << std::endl;
+            std::cout << "---- STACK TRACE ----" << std::endl;
+            std::cout << boost::stacktrace::stacktrace() << std::endl;
+#else
+            std::cout << "cannot show stack trace (.cu source)" << std::endl;
+#endif
             throw CudaException(res);
         }
     }
diff --git a/include/argon2-cuda/kernels.h b/include/argon2-cuda/kernels.h
index 16418b4..1ec0ea8 100644
--- a/include/argon2-cuda/kernels.h
+++ b/include/argon2-cuda/kernels.h
@@ -53,6 +53,8 @@ public:
 
     void writeInputMemory(std::uint32_t jobId, const void *buffer);
     void readOutputMemory(std::uint32_t jobId, void *buffer);
+    void syncStream();
+    bool streamOperationsComplete();
 
     void run(std::uint32_t lanesPerBlock, std::uint32_t jobsPerBlock);
     float finish();
diff --git a/include/argon2-cuda/processingunit.h b/include/argon2-cuda/processingunit.h
index 2109154..b264e92 100644
--- a/include/argon2-cuda/processingunit.h
+++ b/include/argon2-cuda/processingunit.h
@@ -22,6 +22,7 @@ private:
     KernelRunner runner;
     std::uint32_t bestLanesPerBlock;
     std::uint32_t bestJobsPerBlock;
+    std::vector<uint8_t*> setPasswordBuffers;
 
 public:
     std::size_t getBatchSize() const { return runner.getBatchSize(); }
@@ -32,7 +33,11 @@ public:
             bool bySegment = true, bool precomputeRefs = false);
 
     void setPassword(std::size_t index, const void *pw, std::size_t pwSize);
-    void getHash(std::size_t index, void *hash);
+
+    void fetchResultAsync(std::size_t index, void *dest);
+    void processResult(const void *src, void* dst);
+    void syncStream();
+    bool streamOperationsComplete();
 
     void beginProcessing();
     void endProcessing();
diff --git a/include/argon2-gpu-common/argon2-common.h b/include/argon2-gpu-common/argon2-common.h
index fbcf67c..7a849bb 100644
--- a/include/argon2-gpu-common/argon2-common.h
+++ b/include/argon2-gpu-common/argon2-common.h
@@ -1,6 +1,8 @@
 #ifndef ARGON2COMMON_H
 #define ARGON2COMMON_H
 
+#include <cstddef>
+
 namespace argon2 {
 
 enum {
diff --git a/include/argon2-opencl/cl.hpp b/include/argon2-opencl/cl.hpp
index ced34f5..1328b58 100644
--- a/include/argon2-opencl/cl.hpp
+++ b/include/argon2-opencl/cl.hpp
@@ -142,6 +142,12 @@
  * \endcode
  *
  */
+
+#define NOMINMAX
+#include <windows.h>
+#include <boost/stacktrace.hpp>
+#include <iostream>
+
 #ifndef CL_HPP_
 #define CL_HPP_
 
@@ -318,7 +324,6 @@ public:
 #define __ERR_STR(x) NULL
 #endif // __CL_ENABLE_EXCEPTIONS
 
-
 namespace detail
 {
 #if defined(__CL_ENABLE_EXCEPTIONS)
@@ -327,6 +332,11 @@ static inline cl_int errHandler (
     const char * errStr = NULL)
 {
     if (err != CL_SUCCESS) {
+        printf("OpenCL error: errCode=%d str=%s\n", err, errStr ? errStr: "none");
+
+        std::cout << std::endl;
+        std::cout << "---- STACK TRACE ----" << std::endl;
+        std::cout << boost::stacktrace::stacktrace() << std::endl;
         throw Error(err, errStr);
     }
     return err;
diff --git a/lib/argon2-cuda/kernels.cu b/lib/argon2-cuda/kernels.cu
index 79fb767..ac218f3 100644
--- a/lib/argon2-cuda/kernels.cu
+++ b/lib/argon2-cuda/kernels.cu
@@ -49,8 +49,8 @@ __device__ uint64_t u64_shuffle(uint64_t v, uint32_t thread)
 {
     uint32_t lo = u64_lo(v);
     uint32_t hi = u64_hi(v);
-    lo = __shfl(lo, thread);
-    hi = __shfl(hi, thread);
+    lo = __shfl_sync(0xFFFFFFFF, lo, thread);
+    hi = __shfl_sync(0xFFFFFFFF, hi, thread);
     return u64_build(hi, lo);
 }
 
@@ -776,8 +776,8 @@ KernelRunner::KernelRunner(uint32_t type, uint32_t version, uint32_t passes,
 
     CudaException::check(cudaMalloc(&memory, memorySize));
 
-    CudaException::check(cudaEventCreate(&start));
-    CudaException::check(cudaEventCreate(&end));
+//    CudaException::check(cudaEventCreate(&start));
+//    CudaException::check(cudaEventCreate(&end));
 
     CudaException::check(cudaStreamCreate(&stream));
 
@@ -828,12 +828,12 @@ void KernelRunner::precomputeRefs()
 
 KernelRunner::~KernelRunner()
 {
-    if (start != nullptr) {
-        cudaEventDestroy(start);
-    }
-    if (end != nullptr) {
-        cudaEventDestroy(end);
-    }
+    //if (start != nullptr) {
+    //    cudaEventDestroy(start);
+    //}
+    //if (end != nullptr) {
+    //    cudaEventDestroy(end);
+    //}
     if (stream != nullptr) {
         cudaStreamDestroy(stream);
     }
@@ -845,6 +845,24 @@ KernelRunner::~KernelRunner()
     }
 }
 
+void KernelRunner::syncStream() {
+    CudaException::check(cudaStreamSynchronize(stream));
+}
+
+bool KernelRunner::streamOperationsComplete() {
+    cudaError_t res = cudaStreamQuery(stream);
+    if (res == cudaSuccess) {
+        return true;
+    }
+    else if (res == cudaErrorNotReady) {
+        return false;
+    }
+    else {
+        CudaException::check(res);
+        return false;
+    }
+}
+
 void KernelRunner::writeInputMemory(uint32_t jobId, const void *buffer)
 {
     std::size_t memorySize = static_cast<size_t>(lanes) * segmentBlocks
@@ -854,7 +872,7 @@ void KernelRunner::writeInputMemory(uint32_t jobId, const void *buffer)
     auto mem = static_cast<uint8_t *>(memory) + offset;
     CudaException::check(cudaMemcpyAsync(mem, buffer, size,
                                          cudaMemcpyHostToDevice, stream));
-    CudaException::check(cudaStreamSynchronize(stream));
+    //CudaException::check(cudaStreamSynchronize(stream));
 }
 
 void KernelRunner::readOutputMemory(uint32_t jobId, void *buffer)
@@ -866,7 +884,7 @@ void KernelRunner::readOutputMemory(uint32_t jobId, void *buffer)
     auto mem = static_cast<uint8_t *>(memory) + offset;
     CudaException::check(cudaMemcpyAsync(buffer, mem, size,
                                          cudaMemcpyDeviceToHost, stream));
-    CudaException::check(cudaStreamSynchronize(stream));
+//    CudaException::check(cudaStreamSynchronize(stream));
 }
 
 void KernelRunner::runKernelSegment(uint32_t lanesPerBlock,
@@ -1028,7 +1046,7 @@ void KernelRunner::runKernelOneshot(uint32_t lanesPerBlock,
 
 void KernelRunner::run(uint32_t lanesPerBlock, uint32_t jobsPerBlock)
 {
-    CudaException::check(cudaEventRecord(start, stream));
+    //CudaException::check(cudaEventRecord(start, stream));
 
     if (bySegment) {
         for (uint32_t pass = 0; pass < passes; pass++) {
@@ -1042,15 +1060,15 @@ void KernelRunner::run(uint32_t lanesPerBlock, uint32_t jobsPerBlock)
 
     CudaException::check(cudaGetLastError());
 
-    CudaException::check(cudaEventRecord(end, stream));
+    //CudaException::check(cudaEventRecord(end, stream));
 }
 
 float KernelRunner::finish()
 {
-    CudaException::check(cudaStreamSynchronize(stream));
+    //CudaException::check(cudaStreamSynchronize(stream));
 
     float time = 0.0;
-    CudaException::check(cudaEventElapsedTime(&time, start, end));
+    //CudaException::check(cudaEventElapsedTime(&time, start, end));
     return time;
 }
 
diff --git a/lib/argon2-cuda/processingunit.cpp b/lib/argon2-cuda/processingunit.cpp
index 7768427..08800d1 100644
--- a/lib/argon2-cuda/processingunit.cpp
+++ b/lib/argon2-cuda/processingunit.cpp
@@ -24,6 +24,9 @@ static bool isPowerOfTwo(std::uint32_t x)
     return (x & (x - 1)) == 0;
 }
 
+#pragma warning(disable:4267)
+#pragma warning(disable:4101)
+
 ProcessingUnit::ProcessingUnit(
         const ProgramContext *programContext, const Argon2Params *params,
         const Device *device, std::size_t batchSize, bool bySegment,
@@ -36,8 +39,22 @@ ProcessingUnit::ProcessingUnit(
       bestLanesPerBlock(runner.getMinLanesPerBlock()),
       bestJobsPerBlock(runner.getMinJobsPerBlock())
 {
+    // already done by caller, but let's still do it again just in case ...
+    // (it is done by the caller because the runner constructor also needs current device set !)
     setCudaDevice(device->getDeviceIndex());
 
+    // preallocate buffers used by ProcessingUnit::setPassword
+    std::size_t size = params->getLanes() * 2 * ARGON2_BLOCK_SIZE;
+    for (int i = 0; i < batchSize; i++) {
+        uint8_t* ptrPinnedMem = nullptr;
+        cudaError_t status = cudaMallocHost((void**)&(ptrPinnedMem), size);
+        if (status != cudaSuccess) {
+            std::cout << "Error allocating pinned host memory" << std::endl;
+            exit(1);
+        }
+        setPasswordBuffers.push_back(ptrPinnedMem);
+    }
+
     /* pre-fill first blocks with pseudo-random data: */
     for (std::size_t i = 0; i < batchSize; i++) {
         setPassword(i, NULL, 0);
@@ -125,24 +142,34 @@ ProcessingUnit::ProcessingUnit(
 void ProcessingUnit::setPassword(std::size_t index, const void *pw,
                                  std::size_t pwSize)
 {
-    std::size_t size = params->getLanes() * 2 * ARGON2_BLOCK_SIZE;
-    auto buffer = std::unique_ptr<uint8_t[]>(new uint8_t[size]);
-    params->fillFirstBlocks(buffer.get(), pw, pwSize,
+    //std::size_t size = params->getLanes() * 2 * ARGON2_BLOCK_SIZE;
+    //auto buffer = std::unique_ptr<uint8_t[]>(new uint8_t[size]);
+    params->fillFirstBlocks(setPasswordBuffers[index], pw, pwSize,
                             programContext->getArgon2Type(),
                             programContext->getArgon2Version());
-    runner.writeInputMemory(index, buffer.get());
+    runner.writeInputMemory(index, setPasswordBuffers[index]);
 }
 
-void ProcessingUnit::getHash(std::size_t index, void *hash)
-{
+void ProcessingUnit::fetchResultAsync(std::size_t index, void *dest) {
     std::size_t size = params->getLanes() * ARGON2_BLOCK_SIZE;
-    auto buffer = std::unique_ptr<uint8_t[]>(new uint8_t[size]);
-    runner.readOutputMemory(index, buffer.get());
-    params->finalize(hash, buffer.get());
+    runner.readOutputMemory(index, dest);
+}
+
+void ProcessingUnit::processResult(const void *src, void* dst) {
+    params->finalize(dst, src);
+}
+
+void ProcessingUnit::syncStream() {
+    runner.syncStream();
+}
+
+bool ProcessingUnit::streamOperationsComplete() {
+    return runner.streamOperationsComplete();
 }
 
 void ProcessingUnit::beginProcessing()
 {
+    // we MUST set cuda device before launching a kernel
     setCudaDevice(device->getDeviceIndex());
     runner.run(bestLanesPerBlock, bestJobsPerBlock);
 }
diff --git a/lib/argon2-gpu-common/argon2params.cpp b/lib/argon2-gpu-common/argon2params.cpp
index dd122d8..b74c11d 100644
--- a/lib/argon2-gpu-common/argon2params.cpp
+++ b/lib/argon2-gpu-common/argon2params.cpp
@@ -20,6 +20,8 @@ static void store32(void *dst, std::uint32_t v)
     *out++ = static_cast<std::uint8_t>(v);
 }
 
+#pragma warning(disable:4267)
+
 Argon2Params::Argon2Params(
         std::size_t outLen,
         const void *salt, std::size_t saltLen,
diff --git a/lib/argon2-gpu-common/blake2b.h b/lib/argon2-gpu-common/blake2b.h
index 094fb83..7f438ee 100644
--- a/lib/argon2-gpu-common/blake2b.h
+++ b/lib/argon2-gpu-common/blake2b.h
@@ -2,6 +2,7 @@
 #define ARGON2_BLAKE2B_H
 
 #include <cstdint>
+#include <cstddef>
 
 namespace argon2 {
 
diff --git a/lib/argon2-opencl/kernelloader.cpp b/lib/argon2-opencl/kernelloader.cpp
index 22949f3..927a44d 100644
--- a/lib/argon2-opencl/kernelloader.cpp
+++ b/lib/argon2-opencl/kernelloader.cpp
@@ -38,6 +38,7 @@ cl::Program KernelLoader::loadArgon2Program(
         for (cl::Device &device : context.getInfo<CL_CONTEXT_DEVICES>()) {
             std::cerr << "  Build log from device '" << device.getInfo<CL_DEVICE_NAME>() << "':" << std::endl;
             std::cerr << prog.getBuildInfo<CL_PROGRAM_BUILD_LOG>(device);
+			err;
         }
         throw;
     }
diff --git a/lib/argon2-opencl/processingunit.cpp b/lib/argon2-opencl/processingunit.cpp
index 598ced7..59e92a9 100644
--- a/lib/argon2-opencl/processingunit.cpp
+++ b/lib/argon2-opencl/processingunit.cpp
@@ -13,6 +13,9 @@ static bool isPowerOfTwo(std::uint32_t x)
     return (x & (x - 1)) == 0;
 }
 
+#pragma warning(disable:4267)
+#pragma warning(disable:4101)
+
 ProcessingUnit::ProcessingUnit(
         const ProgramContext *programContext, const Argon2Params *params,
         const Device *device, std::size_t batchSize,
